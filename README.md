# Unhurry

![GitHub Release](https://img.shields.io/github/v/release/lumiknit/unhurry)

<p align="center">
  <img src="https://lumiknit.github.io/apps/unhurry/unhurry.png" width="200" height="200" />
</p>

> Unhurry, be lazy.

Simple chat UI with LLM models with some features.

## Download / Web Version

- Download: https://lumiknit.github.io/apps/unhurry/releases/latest
    - Currently, only MacOS & Android are bundled.
- Web Version: https://lumiknit.github.io/apps/unhurry/
    - Because of CORS, some features may not work properly.

## Features

## Usage

1. Go to settings and add your LLM models

- Ollama, openai, gemini, groq, etc. are supported

2. Go to top page and chat.

- You can chat with the models you added.
- If model supports vision + tools (e.g. gemini, gpt-4o), you can update image.
- When 'auto' is enabled. It will automatically send message to the model.
  - With mobile voice keyboard / speech recognition / etc., you can chat with the model without typing.
- There are js & search tools. Model will automatically use them.
- You can add prompt presets as buttons.

# Unhurry

Quick llm chat.

https://lumiknit.github.io/apps/unhurry/

## Usage

1. Go to settings and add your LLM models
  - Ollama, openai, gemini, groq, etc. are supported
2. Go to top page and chat.
  - `run-js` will automatically run the code in the chat box.
	- json, svg, mermaid will be rendered.
